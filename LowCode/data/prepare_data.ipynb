{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8df93412",
   "metadata": {},
   "source": [
    "# Read and process AIS data\n",
    "\n",
    "- Read AIS (ship location) data from the Danish costguard\n",
    "- See ship traffic for a day\n",
    "- Locate any ships sailing into the area between the offshore turbines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66aaa6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "import datetime as dt\n",
    "import json\n",
    "\n",
    "# Data analysis\n",
    "import pandas as pd\n",
    "\n",
    "# Geospatial libraries\n",
    "import geopandas as gpd\n",
    "import pydeck as pdk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff8c4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not Path(\"aisdk-2023-01.zip\").exists():\n",
    "    raise Exception(\"Unable to find AIS data. Please download it from http://web.ais.dk/aisdata/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b32fbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all ship location information for one day\n",
    "with zipfile.ZipFile(\"aisdk-2023-01.zip\") as z:\n",
    "    # Load only the first day\n",
    "    with z.open(\"aisdk-2023-01-01.csv\") as f:\n",
    "        ships = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0f9b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove ships that don't transmit a callsign\n",
    "ships.dropna(subset=('Callsign'), inplace=True)\n",
    "\n",
    "# Clean up raw data\n",
    "ships.sort_values(by=['Callsign', '# Timestamp'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2589e204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all GPS points to a single line for all ships\n",
    "ship_track = []\n",
    "for g in ships.groupby('Callsign')[['Longitude', 'Latitude']]:\n",
    "    path = g[1]\n",
    "    path = path.loc[path['Latitude'] < 70, :]\n",
    "    path = path.to_numpy()[::10].tolist()\n",
    "    if len(path) > 10 and g[0] != \"0\":\n",
    "        ship_track.append({\"Callsign\": str(g[0]), 'path': path})\n",
    "    \n",
    "df_ship_track = pd.DataFrame.from_dict(ship_track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328ddf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load wind turbine offshore locations\n",
    "json = pd.read_json('../../NoCode/data/dk_offshore_sites.geojson')\n",
    "sites = pd.DataFrame()\n",
    "\n",
    "# Parse the geometry out in Pandas\n",
    "sites[\"coordinates\"] = json[\"features\"].apply(lambda row: row[\"geometry\"][\"coordinates\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eec66ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make map\n",
    "view_state = pdk.ViewState(latitude=55.782556, longitude=11.3484867, zoom=5)\n",
    "\n",
    "# Draw ship routes as paths\n",
    "layer = pdk.Layer(\n",
    "    type=\"PathLayer\",\n",
    "    data=df_ship_track,\n",
    "    pickable=True,\n",
    "    width_scale=20,\n",
    "    get_color=(255,255,255),\n",
    "    width_min_pixels=2,\n",
    "    get_path=\"path\",\n",
    "    get_width=5,\n",
    ")\n",
    "\n",
    "# Draw turbine locations as polygons\n",
    "layer_turbines = pdk.Layer(\n",
    "    type=\"PolygonLayer\",\n",
    "    data=sites,\n",
    "    pickable=True,\n",
    "    get_fill_color=[178,34,34],\n",
    "    get_line_color=[255, 255, 255],\n",
    "    get_polygon=\"coordinates\",\n",
    "    opacity=0.8,\n",
    "    auto_highlight=True,\n",
    ")\n",
    "\n",
    "r = pdk.Deck(layers=[layer, layer_turbines], initial_view_state=view_state, tooltip={\"text\": \"{Callsign}\"})\n",
    "r.to_html(\"path_layer.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395aa19d",
   "metadata": {},
   "source": [
    "## Extract all ships that sails into any wind park area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0938499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all ship location information of each available day\n",
    "possible_supply_ships = []\n",
    "with zipfile.ZipFile(\"aisdk-2023-01.zip\") as z:\n",
    "    for fobj in z.filelist:\n",
    "        print(\"Reading file\", fobj.filename)\n",
    "\n",
    "        # Load only the first day\n",
    "        with z.open(fobj) as f:\n",
    "            ships_daily = pd.read_csv(f)\n",
    "\n",
    "            # Remove ships that don't transmit a callsign and ships that transmit strange positions\n",
    "            ships_daily.dropna(subset=('Callsign'), inplace=True)\n",
    "            ships_daily['Callsign'] = ships_daily['Callsign'].astype(str)\n",
    "            ships_daily = ships_daily[ships_daily[\"Callsign\"] != \"0\"]\n",
    "            \n",
    "            # Remove points that are clearly wrong - Denmark doesn't exist above 60 degrees north\n",
    "            ships_daily = ships_daily[ships_daily[\"Latitude\"]<60]\n",
    "\n",
    "            # Find ships that travel into any of the wind park areas using a spatial join\n",
    "            geo_ships = gpd.GeoDataFrame(ships_daily, \n",
    "                                         geometry=gpd.points_from_xy(\n",
    "                                             ships_daily.Longitude,\n",
    "                                             ships_daily.Latitude),\n",
    "                                         crs=\"EPSG:4326\")\n",
    "\n",
    "            # Clean up raw data\n",
    "            ships.sort_values(by=['Callsign', '# Timestamp'], inplace=True)\n",
    "\n",
    "            # Find all ship locations within the wind parks\n",
    "            points_within_site = geo_sites\\\n",
    "                                .sjoin(geo_ships, how='left')\\\n",
    "                                .dropna(subset='MMSI')\n",
    "\n",
    "            ship_names = \"|\".join(points_within_site.Callsign.unique())\n",
    "            print(\"Ships within area\", ship_names)\n",
    "\n",
    "            # Only keep locations from the ships that passed the areas this day\n",
    "            ship_within_area = ships_daily[ships_daily[\"Callsign\"].str.contains(ship_names, regex=True)]\n",
    "            \n",
    "            # Save for later\n",
    "            possible_supply_ships.append(ship_within_area)\n",
    "            \n",
    "know_ships = pd.concat(possible_supply_ships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83091bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "know_ships['# Timestamp'] = pd.to_datetime(know_ships['# Timestamp'], format=\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "for key, ship in know_ships.groupby('Callsign'):\n",
    "    epoch = (ship['# Timestamp'] - dt.datetime(1970,1,1)).dt.total_seconds().astype(int)\n",
    "    coords = pd.concat([ship['Longitude'], ship['Latitude'], epoch], axis=1)\n",
    "    coords.insert(loc=2, column='z', value=0)\n",
    "    \n",
    "    f = {\n",
    "        \"type\": \"Feature\",\n",
    "        \"properties\": {\n",
    "            \"callsign\": key\n",
    "        },\n",
    "        \"geometry\": {\n",
    "            \"type\": \"LineString\",\n",
    "            \"coordinates\": coords.to_numpy().tolist()\n",
    "        }\n",
    "    }\n",
    "    features.append(f)\n",
    "    \n",
    "geojson = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": features\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca3bf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(geojson, open('ships.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ef075f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_timeline(df, resample=1):\n",
    "    features = []\n",
    "    df['# Timestamp'] = pd.to_datetime(df['# Timestamp'], format=\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "    for callsign, ship in df.groupby('Callsign'):\n",
    "        if callsign == \"0\":\n",
    "            # Callsign 0 isn't a ship\n",
    "            continue\n",
    "\n",
    "        # Resample to every N samples\n",
    "        ship = ship.loc[::resample, :]\n",
    "\n",
    "        # Remove duplicates GPS locations (e.g. when ships are docked)\n",
    "        ship = ship.drop_duplicates(subset=[\"Latitude\", \"Longitude\"])\n",
    "        ship = ship[ship[\"Longitude\"] > 0]\n",
    "\n",
    "        # Convert to format for rendering\n",
    "        epoch = (ship['# Timestamp'] - dt.datetime(1970,1,1)).dt.total_seconds().astype(int)\n",
    "        coords = pd.concat([ship['Longitude'], ship['Latitude'], epoch], axis=1)\n",
    "        coords.insert(loc=2, column='z', value=0)\n",
    "\n",
    "        f = {\n",
    "            \"type\": \"Feature\",\n",
    "            \"properties\": {\n",
    "                \"callsign\": callsign\n",
    "            },\n",
    "            \"geometry\": {\n",
    "                \"type\": \"LineString\",\n",
    "                \"coordinates\": coords.to_numpy().tolist()\n",
    "            }\n",
    "        }\n",
    "        features.append(f)\n",
    "\n",
    "    return {\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"features\": features\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e432da1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_day_one = dataframe_to_timeline(ships, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839a8f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(json_day_one, open('ships_Jan_first_2023.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e615127",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
